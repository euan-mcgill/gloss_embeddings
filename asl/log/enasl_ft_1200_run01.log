[2024-03-11 13:12:12,656 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.
[2024-03-11 13:12:12,657 INFO] Parsed 2 corpora from -data.
[2024-03-11 13:12:12,657 INFO] Loading checkpoint from tg-pretrain/models/tg-pretrain_01_step_1200.pt
[2024-03-11 13:12:12,737 INFO] Building model...
[2024-03-11 13:12:12,796 INFO] Switching model to float32 for amp/apex_amp
[2024-03-11 13:12:12,797 INFO] Non quantized layer compute is fp32
[2024-03-11 13:12:14,561 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(17816, 500, padding_idx=1)
        )
      )
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (rnn): LSTM(500, 500, num_layers=2, batch_first=True, dropout=0.3)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(14144, 500, padding_idx=1)
        )
      )
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Linear(in_features=500, out_features=14144, bias=True)
)
[2024-03-11 13:12:14,562 INFO] encoder: 12916000
[2024-03-11 13:12:14,562 INFO] decoder: 19916144
[2024-03-11 13:12:14,562 INFO] * number of parameters: 32832144
[2024-03-11 13:12:14,562 INFO] Trainable parameters = {'torch.float32': 32832144, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-03-11 13:12:14,562 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-03-11 13:12:14,562 INFO]  * src vocab size = 17816
[2024-03-11 13:12:14,562 INFO]  * tgt vocab size = 14144
[2024-03-11 13:12:14,563 INFO] Starting training on GPU: [0]
[2024-03-11 13:12:14,564 INFO] Start training loop and validate every 200 steps...
[2024-03-11 13:12:14,564 INFO] Scoring with: TransformPipe(InferFeatsTransform())
[2024-03-11 13:41:44,190 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.
[2024-03-11 13:41:44,191 INFO] Parsed 2 corpora from -data.
[2024-03-11 13:41:44,191 INFO] Loading checkpoint from tg-pretrain/models/tg-pretrain_01_step_1200.pt
[2024-03-11 13:41:44,266 INFO] Building model...
[2024-03-11 13:41:44,325 INFO] Switching model to float32 for amp/apex_amp
[2024-03-11 13:41:44,325 INFO] Non quantized layer compute is fp32
[2024-03-11 13:41:46,134 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(17816, 500, padding_idx=1)
        )
      )
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (rnn): LSTM(500, 500, num_layers=2, batch_first=True, dropout=0.3)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(14144, 500, padding_idx=1)
        )
      )
      (dropout): Dropout(p=0.3, inplace=False)
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Linear(in_features=500, out_features=14144, bias=True)
)
[2024-03-11 13:41:46,135 INFO] encoder: 12916000
[2024-03-11 13:41:46,135 INFO] decoder: 19916144
[2024-03-11 13:41:46,135 INFO] * number of parameters: 32832144
[2024-03-11 13:41:46,135 INFO] Trainable parameters = {'torch.float32': 32832144, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-03-11 13:41:46,135 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-03-11 13:41:46,135 INFO]  * src vocab size = 17816
[2024-03-11 13:41:46,135 INFO]  * tgt vocab size = 14144
[2024-03-11 13:41:46,137 INFO] Starting training on GPU: [0]
[2024-03-11 13:41:46,137 INFO] Start training loop and validate every 200 steps...
[2024-03-11 13:41:46,138 INFO] Scoring with: TransformPipe(InferFeatsTransform())
[2024-03-11 13:41:53,334 INFO] Step 1250/ 6200; acc: 12.7; ppl: 4826.4; xent: 8.5; lr: 1.00000; sents:    2270; bsz:  565/ 490/45; 3927/3403 tok/s;      7 sec;
[2024-03-11 13:41:56,908 INFO] Step 1300/ 6200; acc: 16.8; ppl: 630.7; xent: 6.4; lr: 1.00000; sents:    2369; bsz:  569/ 496/47; 7957/6940 tok/s;     11 sec;
[2024-03-11 13:42:00,393 INFO] Step 1350/ 6200; acc: 19.3; ppl: 328.3; xent: 5.8; lr: 1.00000; sents:    2363; bsz:  585/ 508/47; 8395/7287 tok/s;     14 sec;
[2024-03-11 13:42:02,717 INFO] Step 1400/ 6200; acc: 24.7; ppl: 165.4; xent: 5.1; lr: 1.00000; sents:    2365; bsz:  563/ 489/47; 12107/10517 tok/s;     17 sec;
[2024-03-11 13:42:06,169 INFO] valid stats calculation
                           took: 3.4517822265625 s.
[2024-03-11 13:42:06,170 INFO] Train perplexity: 634.122
[2024-03-11 13:42:06,170 INFO] Train accuracy: 18.3914
[2024-03-11 13:42:06,170 INFO] Sentences processed: 9367
[2024-03-11 13:42:06,170 INFO] Average bsz:  570/ 496/47
[2024-03-11 13:42:06,170 INFO] Validation perplexity: 320.133
[2024-03-11 13:42:06,170 INFO] Validation accuracy: 23.0245
[2024-03-11 13:42:06,171 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_1400.pt
[2024-03-11 13:42:09,927 INFO] Step 1450/ 6200; acc: 27.1; ppl: 115.7; xent: 4.8; lr: 1.00000; sents:    2367; bsz:  587/ 509/47; 4069/3533 tok/s;     24 sec;
[2024-03-11 13:42:13,540 INFO] Step 1500/ 6200; acc: 31.4; ppl:  69.5; xent: 4.2; lr: 1.00000; sents:    2251; bsz:  549/ 475/45; 7600/6572 tok/s;     27 sec;
[2024-03-11 13:42:17,285 INFO] Step 1550/ 6200; acc: 33.5; ppl:  51.1; xent: 3.9; lr: 1.00000; sents:    2378; bsz:  586/ 509/48; 7818/6796 tok/s;     31 sec;
[2024-03-11 13:42:19,918 INFO] Step 1600/ 6200; acc: 36.8; ppl:  34.5; xent: 3.5; lr: 1.00000; sents:    2280; bsz:  544/ 473/46; 10335/8980 tok/s;     34 sec;
[2024-03-11 13:42:23,544 INFO] valid stats calculation
                           took: 3.6254971027374268 s.
[2024-03-11 13:42:23,544 INFO] Train perplexity: 199.017
[2024-03-11 13:42:23,544 INFO] Train accuracy: 25.2416
[2024-03-11 13:42:23,544 INFO] Sentences processed: 18643
[2024-03-11 13:42:23,544 INFO] Average bsz:  568/ 494/47
[2024-03-11 13:42:23,544 INFO] Validation perplexity: 380.702
[2024-03-11 13:42:23,544 INFO] Validation accuracy: 22.6635
[2024-03-11 13:42:23,546 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_1600.pt
[2024-03-11 13:42:27,340 INFO] Step 1650/ 6200; acc: 38.9; ppl:  28.5; xent: 3.4; lr: 1.00000; sents:    2381; bsz:  586/ 509/48; 3951/3432 tok/s;     41 sec;
[2024-03-11 13:42:30,908 INFO] Step 1700/ 6200; acc: 41.4; ppl:  22.1; xent: 3.1; lr: 1.00000; sents:    2261; bsz:  552/ 477/45; 7734/6683 tok/s;     45 sec;
[2024-03-11 13:42:34,506 INFO] Step 1750/ 6200; acc: 44.7; ppl:  16.8; xent: 2.8; lr: 1.00000; sents:    2372; bsz:  580/ 502/47; 8060/6977 tok/s;     48 sec;
[2024-03-11 13:42:37,352 INFO] Step 1800/ 6200; acc: 47.0; ppl:  13.9; xent: 2.6; lr: 1.00000; sents:    2366; bsz:  562/ 489/47; 9878/8595 tok/s;     51 sec;
[2024-03-11 13:42:40,820 INFO] valid stats calculation
                           took: 3.4677212238311768 s.
[2024-03-11 13:42:40,820 INFO] Train perplexity: 91.844
[2024-03-11 13:42:40,821 INFO] Train accuracy: 31.156
[2024-03-11 13:42:40,821 INFO] Sentences processed: 28023
[2024-03-11 13:42:40,821 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:42:40,821 INFO] Validation perplexity: 358.826
[2024-03-11 13:42:40,821 INFO] Validation accuracy: 26.9555
[2024-03-11 13:42:40,822 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_1800.pt
[2024-03-11 13:42:44,638 INFO] Step 1850/ 6200; acc: 48.5; ppl:  12.4; xent: 2.5; lr: 1.00000; sents:    2271; bsz:  567/ 491/45; 3890/3367 tok/s;     59 sec;
[2024-03-11 13:42:48,280 INFO] Step 1900/ 6200; acc: 51.2; ppl:  10.1; xent: 2.3; lr: 1.00000; sents:    2364; bsz:  567/ 499/47; 7792/6858 tok/s;     62 sec;
[2024-03-11 13:42:52,012 INFO] Step 1950/ 6200; acc: 53.0; ppl:   8.9; xent: 2.2; lr: 1.00000; sents:    2367; bsz:  587/ 512/47; 7864/6863 tok/s;     66 sec;
[2024-03-11 13:42:54,999 INFO] Step 2000/ 6200; acc: 55.9; ppl:   7.2; xent: 2.0; lr: 1.00000; sents:    2261; bsz:  554/ 479/45; 9277/8013 tok/s;     69 sec;
[2024-03-11 13:42:58,702 INFO] valid stats calculation
                           took: 3.703282356262207 s.
[2024-03-11 13:42:58,703 INFO] Train perplexity: 51.987
[2024-03-11 13:42:58,703 INFO] Train accuracy: 36.407
[2024-03-11 13:42:58,703 INFO] Sentences processed: 37286
[2024-03-11 13:42:58,703 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:42:58,703 INFO] Validation perplexity: 461.66
[2024-03-11 13:42:58,703 INFO] Validation accuracy: 28.0786
[2024-03-11 13:42:58,704 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_2000.pt
[2024-03-11 13:43:02,543 INFO] Step 2050/ 6200; acc: 58.4; ppl:   6.1; xent: 1.8; lr: 1.00000; sents:    2373; bsz:  563/ 490/47; 3734/3246 tok/s;     76 sec;
[2024-03-11 13:43:06,256 INFO] Step 2100/ 6200; acc: 59.9; ppl:   5.6; xent: 1.7; lr: 1.00000; sents:    2371; bsz:  576/ 500/47; 7750/6738 tok/s;     80 sec;
[2024-03-11 13:43:10,009 INFO] Step 2150/ 6200; acc: 61.9; ppl:   4.9; xent: 1.6; lr: 1.00000; sents:    2376; bsz:  565/ 495/48; 7533/6596 tok/s;     84 sec;
[2024-03-11 13:43:12,982 INFO] Step 2200/ 6200; acc: 62.9; ppl:   4.6; xent: 1.5; lr: 1.00000; sents:    2284; bsz:  579/ 498/46; 9743/8370 tok/s;     87 sec;
[2024-03-11 13:43:16,589 INFO] valid stats calculation
                           took: 3.6064155101776123 s.
[2024-03-11 13:43:16,589 INFO] Train perplexity: 32.8597
[2024-03-11 13:43:16,589 INFO] Train accuracy: 41.2911
[2024-03-11 13:43:16,589 INFO] Sentences processed: 46690
[2024-03-11 13:43:16,589 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:43:16,589 INFO] Validation perplexity: 645.909
[2024-03-11 13:43:16,589 INFO] Validation accuracy: 29.3622
[2024-03-11 13:43:16,591 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_2200.pt
[2024-03-11 13:43:20,437 INFO] Step 2250/ 6200; acc: 65.6; ppl:   4.0; xent: 1.4; lr: 1.00000; sents:    2376; bsz:  564/ 493/48; 3786/3307 tok/s;     94 sec;
[2024-03-11 13:43:24,085 INFO] Step 2300/ 6200; acc: 67.0; ppl:   3.7; xent: 1.3; lr: 1.00000; sents:    2275; bsz:  561/ 484/46; 7693/6638 tok/s;     98 sec;
[2024-03-11 13:43:27,711 INFO] Step 2350/ 6200; acc: 69.3; ppl:   3.3; xent: 1.2; lr: 1.00000; sents:    2471; bsz:  582/ 504/49; 8034/6954 tok/s;    102 sec;
[2024-03-11 13:43:30,849 INFO] Step 2400/ 6200; acc: 69.7; ppl:   3.2; xent: 1.2; lr: 1.00000; sents:    2266; bsz:  559/ 484/45; 8905/7718 tok/s;    105 sec;
[2024-03-11 13:43:34,424 INFO] valid stats calculation
                           took: 3.574862480163574 s.
[2024-03-11 13:43:34,425 INFO] Train perplexity: 22.705
[2024-03-11 13:43:34,425 INFO] Train accuracy: 45.7054
[2024-03-11 13:43:34,425 INFO] Sentences processed: 56078
[2024-03-11 13:43:34,425 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:43:34,425 INFO] Validation perplexity: 860.565
[2024-03-11 13:43:34,425 INFO] Validation accuracy: 29.0012
[2024-03-11 13:43:34,426 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_2400.pt
[2024-03-11 13:43:38,121 INFO] Step 2450/ 6200; acc: 72.2; ppl:   2.9; xent: 1.1; lr: 1.00000; sents:    2366; bsz:  564/ 490/47; 3879/3372 tok/s;    112 sec;
[2024-03-11 13:43:41,782 INFO] Step 2500/ 6200; acc: 72.8; ppl:   2.8; xent: 1.0; lr: 1.00000; sents:    2264; bsz:  562/ 487/45; 7671/6648 tok/s;    116 sec;
[2024-03-11 13:43:45,495 INFO] Step 2550/ 6200; acc: 73.5; ppl:   2.7; xent: 1.0; lr: 1.00000; sents:    2369; bsz:  586/ 507/47; 7894/6826 tok/s;    119 sec;
[2024-03-11 13:43:48,921 INFO] Step 2600/ 6200; acc: 75.7; ppl:   2.5; xent: 0.9; lr: 1.00000; sents:    2267; bsz:  561/ 483/45; 8191/7055 tok/s;    123 sec;
[2024-03-11 13:43:52,546 INFO] valid stats calculation
                           took: 3.6245546340942383 s.
[2024-03-11 13:43:52,546 INFO] Train perplexity: 16.7844
[2024-03-11 13:43:52,546 INFO] Train accuracy: 49.6683
[2024-03-11 13:43:52,546 INFO] Sentences processed: 65344
[2024-03-11 13:43:52,546 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:43:52,546 INFO] Validation perplexity: 1111.12
[2024-03-11 13:43:52,546 INFO] Validation accuracy: 27.8379
[2024-03-11 13:43:52,548 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_2600.pt
[2024-03-11 13:43:56,309 INFO] Step 2650/ 6200; acc: 76.7; ppl:   2.4; xent: 0.9; lr: 1.00000; sents:    2372; bsz:  580/ 501/47; 3929/3393 tok/s;    130 sec;
[2024-03-11 13:44:00,002 INFO] Step 2700/ 6200; acc: 78.4; ppl:   2.2; xent: 0.8; lr: 1.00000; sents:    2371; bsz:  564/ 490/47; 7637/6628 tok/s;    134 sec;
[2024-03-11 13:44:03,643 INFO] Step 2750/ 6200; acc: 79.0; ppl:   2.1; xent: 0.8; lr: 1.00000; sents:    2375; bsz:  566/ 493/48; 7776/6769 tok/s;    138 sec;
[2024-03-11 13:44:07,230 INFO] Step 2800/ 6200; acc: 80.3; ppl:   2.1; xent: 0.7; lr: 1.00000; sents:    2382; bsz:  582/ 504/48; 8113/7021 tok/s;    141 sec;
[2024-03-11 13:44:10,832 INFO] valid stats calculation
                           took: 3.6018435955047607 s.
[2024-03-11 13:44:10,832 INFO] Train perplexity: 12.9938
[2024-03-11 13:44:10,832 INFO] Train accuracy: 53.3024
[2024-03-11 13:44:10,832 INFO] Sentences processed: 74844
[2024-03-11 13:44:10,832 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:44:10,833 INFO] Validation perplexity: 1461.61
[2024-03-11 13:44:10,833 INFO] Validation accuracy: 29.3221
[2024-03-11 13:44:10,834 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_2800.pt
[2024-03-11 13:44:14,694 INFO] Step 2850/ 6200; acc: 80.3; ppl:   2.0; xent: 0.7; lr: 1.00000; sents:    2274; bsz:  557/ 483/45; 3735/3238 tok/s;    149 sec;
[2024-03-11 13:44:18,313 INFO] Step 2900/ 6200; acc: 82.1; ppl:   1.9; xent: 0.6; lr: 1.00000; sents:    2376; bsz:  568/ 496/48; 7853/6852 tok/s;    152 sec;
[2024-03-11 13:44:22,012 INFO] Step 2950/ 6200; acc: 82.9; ppl:   1.8; xent: 0.6; lr: 1.00000; sents:    2272; bsz:  563/ 488/45; 7613/6603 tok/s;    156 sec;
[2024-03-11 13:44:25,811 INFO] Step 3000/ 6200; acc: 82.9; ppl:   1.9; xent: 0.6; lr: 1.00000; sents:    2366; bsz:  589/ 511/47; 7752/6725 tok/s;    160 sec;
[2024-03-11 13:44:29,438 INFO] valid stats calculation
                           took: 3.6265580654144287 s.
[2024-03-11 13:44:29,439 INFO] Train perplexity: 10.4935
[2024-03-11 13:44:29,439 INFO] Train accuracy: 56.5027
[2024-03-11 13:44:29,439 INFO] Sentences processed: 84132
[2024-03-11 13:44:29,439 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:44:29,439 INFO] Validation perplexity: 2172.4
[2024-03-11 13:44:29,439 INFO] Validation accuracy: 28.8408
[2024-03-11 13:44:29,441 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_3000.pt
[2024-03-11 13:44:33,212 INFO] Step 3050/ 6200; acc: 83.8; ppl:   1.8; xent: 0.6; lr: 1.00000; sents:    2369; bsz:  587/ 508/47; 3966/3431 tok/s;    167 sec;
[2024-03-11 13:44:36,794 INFO] Step 3100/ 6200; acc: 85.3; ppl:   1.7; xent: 0.5; lr: 1.00000; sents:    2242; bsz:  527/ 458/45; 7351/6389 tok/s;    171 sec;
[2024-03-11 13:44:40,464 INFO] Step 3150/ 6200; acc: 85.0; ppl:   1.7; xent: 0.5; lr: 1.00000; sents:    2365; bsz:  585/ 508/47; 7975/6920 tok/s;    174 sec;
[2024-03-11 13:44:44,235 INFO] Step 3200/ 6200; acc: 85.7; ppl:   1.7; xent: 0.5; lr: 1.00000; sents:    2258; bsz:  553/ 479/45; 7332/6349 tok/s;    178 sec;
[2024-03-11 13:44:47,804 INFO] valid stats calculation
                           took: 3.568291187286377 s.
[2024-03-11 13:44:47,804 INFO] Train perplexity: 8.76928
[2024-03-11 13:44:47,804 INFO] Train accuracy: 59.3133
[2024-03-11 13:44:47,804 INFO] Sentences processed: 93366
[2024-03-11 13:44:47,804 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:44:47,804 INFO] Validation perplexity: 2868.27
[2024-03-11 13:44:47,804 INFO] Validation accuracy: 29.0012
[2024-03-11 13:44:47,806 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_3200.pt
[2024-03-11 13:44:51,407 INFO] Step 3250/ 6200; acc: 85.8; ppl:   1.6; xent: 0.5; lr: 1.00000; sents:    2377; bsz:  584/ 507/48; 4073/3532 tok/s;    185 sec;
[2024-03-11 13:44:55,108 INFO] Step 3300/ 6200; acc: 86.8; ppl:   1.6; xent: 0.5; lr: 1.00000; sents:    2379; bsz:  568/ 494/48; 7674/6682 tok/s;    189 sec;
[2024-03-11 13:44:58,838 INFO] Step 3350/ 6200; acc: 86.7; ppl:   1.6; xent: 0.5; lr: 1.00000; sents:    2383; bsz:  583/ 507/48; 7817/6793 tok/s;    193 sec;
[2024-03-11 13:45:02,564 INFO] Step 3400/ 6200; acc: 87.3; ppl:   1.6; xent: 0.5; lr: 1.00000; sents:    2267; bsz:  555/ 479/45; 7443/6433 tok/s;    196 sec;
[2024-03-11 13:45:06,139 INFO] valid stats calculation
                           took: 3.574838161468506 s.
[2024-03-11 13:45:06,139 INFO] Train perplexity: 7.50555
[2024-03-11 13:45:06,140 INFO] Train accuracy: 61.8121
[2024-03-11 13:45:06,140 INFO] Sentences processed: 102772
[2024-03-11 13:45:06,140 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:45:06,140 INFO] Validation perplexity: 4326.68
[2024-03-11 13:45:06,140 INFO] Validation accuracy: 27.9984
[2024-03-11 13:45:06,141 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_3400.pt
[2024-03-11 13:45:09,407 INFO] Step 3450/ 6200; acc: 88.2; ppl:   1.5; xent: 0.4; lr: 1.00000; sents:    2375; bsz:  563/ 489/48; 4115/3574 tok/s;    203 sec;
[2024-03-11 13:45:13,261 INFO] Step 3500/ 6200; acc: 87.7; ppl:   1.5; xent: 0.4; lr: 1.00000; sents:    2372; bsz:  586/ 513/47; 7605/6658 tok/s;    207 sec;
[2024-03-11 13:45:17,121 INFO] Step 3550/ 6200; acc: 89.4; ppl:   1.5; xent: 0.4; lr: 1.00000; sents:    2366; bsz:  567/ 497/47; 7345/6439 tok/s;    211 sec;
[2024-03-11 13:45:20,982 INFO] Step 3600/ 6200; acc: 89.0; ppl:   1.5; xent: 0.4; lr: 1.00000; sents:    2271; bsz:  568/ 493/45; 7359/6389 tok/s;    215 sec;
[2024-03-11 13:45:24,566 INFO] valid stats calculation
                           took: 3.5829169750213623 s.
[2024-03-11 13:45:24,566 INFO] Train perplexity: 6.55505
[2024-03-11 13:45:24,566 INFO] Train accuracy: 64.0608
[2024-03-11 13:45:24,566 INFO] Sentences processed: 112156
[2024-03-11 13:45:24,566 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:45:24,566 INFO] Validation perplexity: 4307.85
[2024-03-11 13:45:24,566 INFO] Validation accuracy: 28.1588
[2024-03-11 13:45:24,568 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_3600.pt
[2024-03-11 13:45:27,781 INFO] Step 3650/ 6200; acc: 88.8; ppl:   1.5; xent: 0.4; lr: 1.00000; sents:    2364; bsz:  573/ 494/47; 4214/3633 tok/s;    222 sec;
[2024-03-11 13:45:31,485 INFO] Step 3700/ 6200; acc: 89.7; ppl:   1.4; xent: 0.4; lr: 1.00000; sents:    2263; bsz:  553/ 479/45; 7471/6463 tok/s;    225 sec;
[2024-03-11 13:45:35,126 INFO] Step 3750/ 6200; acc: 90.1; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2365; bsz:  562/ 489/47; 7711/6715 tok/s;    229 sec;
[2024-03-11 13:45:38,862 INFO] Step 3800/ 6200; acc: 89.8; ppl:   1.4; xent: 0.4; lr: 1.00000; sents:    2373; bsz:  567/ 495/47; 7584/6632 tok/s;    233 sec;
[2024-03-11 13:45:42,366 INFO] valid stats calculation
                           took: 3.503934860229492 s.
[2024-03-11 13:45:42,367 INFO] Train perplexity: 5.8407
[2024-03-11 13:45:42,367 INFO] Train accuracy: 66.0057
[2024-03-11 13:45:42,368 INFO] Sentences processed: 121521
[2024-03-11 13:45:42,368 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:45:42,368 INFO] Validation perplexity: 5605.25
[2024-03-11 13:45:42,368 INFO] Validation accuracy: 28.8408
[2024-03-11 13:45:42,369 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_3800.pt
[2024-03-11 13:45:45,446 INFO] Step 3850/ 6200; acc: 90.1; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2275; bsz:  578/ 497/46; 4386/3774 tok/s;    239 sec;
[2024-03-11 13:45:49,309 INFO] Step 3900/ 6200; acc: 90.6; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2375; bsz:  565/ 494/48; 7314/6401 tok/s;    243 sec;
[2024-03-11 13:45:53,063 INFO] Step 3950/ 6200; acc: 90.2; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2281; bsz:  563/ 486/46; 7493/6473 tok/s;    247 sec;
[2024-03-11 13:45:56,667 INFO] Step 4000/ 6200; acc: 90.8; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2476; bsz:  582/ 503/50; 8071/6985 tok/s;    251 sec;
[2024-03-11 13:46:00,270 INFO] valid stats calculation
                           took: 3.602458953857422 s.
[2024-03-11 13:46:00,270 INFO] Train perplexity: 5.27284
[2024-03-11 13:46:00,270 INFO] Train accuracy: 67.7536
[2024-03-11 13:46:00,270 INFO] Sentences processed: 130928
[2024-03-11 13:46:00,271 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:46:00,271 INFO] Validation perplexity: 4632.7
[2024-03-11 13:46:00,271 INFO] Validation accuracy: 28.7605
[2024-03-11 13:46:00,272 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_4000.pt
[2024-03-11 13:46:03,216 INFO] Step 4050/ 6200; acc: 90.9; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2275; bsz:  562/ 485/46; 4292/3706 tok/s;    257 sec;
[2024-03-11 13:46:07,128 INFO] Step 4100/ 6200; acc: 90.9; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2371; bsz:  586/ 508/47; 7493/6494 tok/s;    261 sec;
[2024-03-11 13:46:10,861 INFO] Step 4150/ 6200; acc: 91.0; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2268; bsz:  563/ 487/45; 7535/6527 tok/s;    265 sec;
[2024-03-11 13:46:14,452 INFO] Step 4200/ 6200; acc: 91.5; ppl:   1.4; xent: 0.3; lr: 1.00000; sents:    2366; bsz:  564/ 490/47; 7860/6830 tok/s;    268 sec;
[2024-03-11 13:46:17,981 INFO] valid stats calculation
                           took: 3.528827667236328 s.
[2024-03-11 13:46:17,982 INFO] Train perplexity: 4.82036
[2024-03-11 13:46:17,982 INFO] Train accuracy: 69.3061
[2024-03-11 13:46:17,982 INFO] Sentences processed: 140208
[2024-03-11 13:46:17,982 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:46:17,982 INFO] Validation perplexity: 6457.21
[2024-03-11 13:46:17,982 INFO] Validation accuracy: 29.282
[2024-03-11 13:46:17,983 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_4200.pt
[2024-03-11 13:46:20,653 INFO] Step 4250/ 6200; acc: 91.7; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2262; bsz:  560/ 483/45; 4515/3893 tok/s;    275 sec;
[2024-03-11 13:46:24,316 INFO] Step 4300/ 6200; acc: 91.6; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2367; bsz:  580/ 500/47; 7915/6829 tok/s;    278 sec;
[2024-03-11 13:46:27,912 INFO] Step 4350/ 6200; acc: 92.1; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2369; bsz:  563/ 489/47; 7834/6798 tok/s;    282 sec;
[2024-03-11 13:46:31,581 INFO] Step 4400/ 6200; acc: 91.9; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2270; bsz:  559/ 485/45; 7621/6611 tok/s;    285 sec;
[2024-03-11 13:46:35,074 INFO] valid stats calculation
                           took: 3.4924302101135254 s.
[2024-03-11 13:46:35,074 INFO] Train perplexity: 4.45137
[2024-03-11 13:46:35,074 INFO] Train accuracy: 70.7016
[2024-03-11 13:46:35,075 INFO] Sentences processed: 149476
[2024-03-11 13:46:35,075 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:46:35,075 INFO] Validation perplexity: 7862.27
[2024-03-11 13:46:35,075 INFO] Validation accuracy: 28.9611
[2024-03-11 13:46:35,076 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_4400.pt
[2024-03-11 13:46:37,614 INFO] Step 4450/ 6200; acc: 92.0; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2371; bsz:  566/ 493/47; 4689/4086 tok/s;    291 sec;
[2024-03-11 13:46:41,089 INFO] Step 4500/ 6200; acc: 92.7; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2375; bsz:  582/ 503/48; 8374/7244 tok/s;    295 sec;
[2024-03-11 13:46:44,782 INFO] Step 4550/ 6200; acc: 92.4; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2279; bsz:  561/ 487/46; 7603/6595 tok/s;    299 sec;
[2024-03-11 13:46:48,571 INFO] Step 4600/ 6200; acc: 92.2; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2378; bsz:  590/ 512/48; 7786/6753 tok/s;    302 sec;
[2024-03-11 13:46:52,016 INFO] valid stats calculation
                           took: 3.444981098175049 s.
[2024-03-11 13:46:52,017 INFO] Train perplexity: 4.13902
[2024-03-11 13:46:52,017 INFO] Train accuracy: 71.9868
[2024-03-11 13:46:52,017 INFO] Sentences processed: 158879
[2024-03-11 13:46:52,017 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:46:52,017 INFO] Validation perplexity: 7291.38
[2024-03-11 13:46:52,017 INFO] Validation accuracy: 29.1617
[2024-03-11 13:46:52,018 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_4600.pt
[2024-03-11 13:46:54,601 INFO] Step 4650/ 6200; acc: 92.8; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2381; bsz:  572/ 499/48; 4743/4140 tok/s;    308 sec;
[2024-03-11 13:46:57,798 INFO] Step 4700/ 6200; acc: 92.7; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2368; bsz:  585/ 506/47; 9154/7921 tok/s;    312 sec;
[2024-03-11 13:47:01,488 INFO] Step 4750/ 6200; acc: 92.6; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2246; bsz:  550/ 476/45; 7450/6447 tok/s;    315 sec;
[2024-03-11 13:47:05,126 INFO] Step 4800/ 6200; acc: 93.0; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2368; bsz:  567/ 493/47; 7790/6780 tok/s;    319 sec;
[2024-03-11 13:47:08,596 INFO] valid stats calculation
                           took: 3.470345973968506 s.
[2024-03-11 13:47:08,597 INFO] Train perplexity: 3.87963
[2024-03-11 13:47:08,597 INFO] Train accuracy: 73.1425
[2024-03-11 13:47:08,597 INFO] Sentences processed: 168242
[2024-03-11 13:47:08,597 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:47:08,597 INFO] Validation perplexity: 7689.16
[2024-03-11 13:47:08,597 INFO] Validation accuracy: 30.1645
[2024-03-11 13:47:08,598 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_4800.pt
[2024-03-11 13:47:11,429 INFO] Step 4850/ 6200; acc: 92.8; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2363; bsz:  562/ 488/47; 4455/3873 tok/s;    325 sec;
[2024-03-11 13:47:14,345 INFO] Step 4900/ 6200; acc: 92.8; ppl:   1.3; xent: 0.3; lr: 1.00000; sents:    2251; bsz:  567/ 490/45; 9724/8397 tok/s;    328 sec;
[2024-03-11 13:47:18,047 INFO] Step 4950/ 6200; acc: 93.2; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2372; bsz:  566/ 492/47; 7640/6641 tok/s;    332 sec;
[2024-03-11 13:47:21,797 INFO] Step 5000/ 6200; acc: 93.3; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2377; bsz:  569/ 497/48; 7583/6632 tok/s;    336 sec;
[2024-03-11 13:47:25,248 INFO] valid stats calculation
                           took: 3.450255870819092 s.
[2024-03-11 13:47:25,248 INFO] Train perplexity: 3.66042
[2024-03-11 13:47:25,248 INFO] Train accuracy: 74.1842
[2024-03-11 13:47:25,248 INFO] Sentences processed: 177605
[2024-03-11 13:47:25,248 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:47:25,248 INFO] Validation perplexity: 11039.3
[2024-03-11 13:47:25,248 INFO] Validation accuracy: 28.8006
[2024-03-11 13:47:25,249 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_5000.pt
[2024-03-11 13:47:28,421 INFO] Step 5050/ 6200; acc: 93.6; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2379; bsz:  583/ 509/48; 4404/3844 tok/s;    342 sec;
[2024-03-11 13:47:31,144 INFO] Step 5100/ 6200; acc: 93.3; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2274; bsz:  555/ 478/45; 10199/8785 tok/s;    345 sec;
[2024-03-11 13:47:34,909 INFO] Step 5150/ 6200; acc: 93.6; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2376; bsz:  583/ 509/48; 7747/6756 tok/s;    349 sec;
[2024-03-11 13:47:38,666 INFO] Step 5200/ 6200; acc: 93.5; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2278; bsz:  548/ 473/46; 7292/6303 tok/s;    353 sec;
[2024-03-11 13:47:42,169 INFO] valid stats calculation
                           took: 3.502455949783325 s.
[2024-03-11 13:47:42,169 INFO] Train perplexity: 3.4708
[2024-03-11 13:47:42,169 INFO] Train accuracy: 75.1474
[2024-03-11 13:47:42,169 INFO] Sentences processed: 186912
[2024-03-11 13:47:42,169 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:47:42,169 INFO] Validation perplexity: 13661.2
[2024-03-11 13:47:42,169 INFO] Validation accuracy: 28.8809
[2024-03-11 13:47:42,170 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_5200.pt
[2024-03-11 13:47:45,488 INFO] Step 5250/ 6200; acc: 93.5; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2372; bsz:  587/ 515/47; 4304/3776 tok/s;    359 sec;
[2024-03-11 13:47:47,937 INFO] Step 5300/ 6200; acc: 93.6; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2367; bsz:  563/ 489/47; 11487/9982 tok/s;    362 sec;
[2024-03-11 13:47:51,731 INFO] Step 5350/ 6200; acc: 93.5; ppl:   1.3; xent: 0.2; lr: 1.00000; sents:    2263; bsz:  571/ 490/45; 7526/6454 tok/s;    366 sec;
[2024-03-11 13:47:55,364 INFO] Step 5400/ 6200; acc: 93.9; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2364; bsz:  558/ 487/47; 7681/6698 tok/s;    369 sec;
[2024-03-11 13:47:58,827 INFO] valid stats calculation
                           took: 3.46201229095459 s.
[2024-03-11 13:47:58,827 INFO] Train perplexity: 3.30586
[2024-03-11 13:47:58,827 INFO] Train accuracy: 76.0292
[2024-03-11 13:47:58,827 INFO] Sentences processed: 196278
[2024-03-11 13:47:58,827 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:47:58,827 INFO] Validation perplexity: 11076.2
[2024-03-11 13:47:58,827 INFO] Validation accuracy: 28.199
[2024-03-11 13:47:58,829 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_5400.pt
[2024-03-11 13:48:02,483 INFO] Step 5450/ 6200; acc: 93.6; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2367; bsz:  578/ 503/47; 4061/3534 tok/s;    376 sec;
[2024-03-11 13:48:04,919 INFO] Step 5500/ 6200; acc: 94.1; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2268; bsz:  546/ 473/45; 11207/9712 tok/s;    379 sec;
[2024-03-11 13:48:08,572 INFO] Step 5550/ 6200; acc: 93.8; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2373; bsz:  581/ 507/47; 7955/6936 tok/s;    382 sec;
[2024-03-11 13:48:12,372 INFO] Step 5600/ 6200; acc: 94.1; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2372; bsz:  565/ 491/47; 7438/6459 tok/s;    386 sec;
[2024-03-11 13:48:15,830 INFO] valid stats calculation
                           took: 3.4566547870635986 s.
[2024-03-11 13:48:15,830 INFO] Train perplexity: 3.16163
[2024-03-11 13:48:15,830 INFO] Train accuracy: 76.8411
[2024-03-11 13:48:15,830 INFO] Sentences processed: 205658
[2024-03-11 13:48:15,830 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:48:15,830 INFO] Validation perplexity: 15207.2
[2024-03-11 13:48:15,830 INFO] Validation accuracy: 29.282
[2024-03-11 13:48:15,831 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_5600.pt
[2024-03-11 13:48:19,619 INFO] Step 5650/ 6200; acc: 94.3; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2274; bsz:  578/ 496/45; 3989/3424 tok/s;    393 sec;
[2024-03-11 13:48:22,036 INFO] Step 5700/ 6200; acc: 94.2; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2382; bsz:  561/ 487/48; 11602/10081 tok/s;    396 sec;
[2024-03-11 13:48:25,426 INFO] Step 5750/ 6200; acc: 94.0; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2276; bsz:  565/ 488/46; 8335/7206 tok/s;    399 sec;
[2024-03-11 13:48:29,233 INFO] Step 5800/ 6200; acc: 94.2; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2377; bsz:  588/ 509/48; 7721/6684 tok/s;    403 sec;
[2024-03-11 13:48:32,672 INFO] valid stats calculation
                           took: 3.438246726989746 s.
[2024-03-11 13:48:32,672 INFO] Train perplexity: 3.03408
[2024-03-11 13:48:32,672 INFO] Train accuracy: 77.5976
[2024-03-11 13:48:32,672 INFO] Sentences processed: 214967
[2024-03-11 13:48:32,672 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:48:32,672 INFO] Validation perplexity: 12228.4
[2024-03-11 13:48:32,672 INFO] Validation accuracy: 28.3594
[2024-03-11 13:48:32,674 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_5800.pt
[2024-03-11 13:48:36,501 INFO] Step 5850/ 6200; acc: 94.3; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2371; bsz:  565/ 491/47; 3889/3378 tok/s;    410 sec;
[2024-03-11 13:48:38,995 INFO] Step 5900/ 6200; acc: 94.1; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2366; bsz:  563/ 489/47; 11284/9810 tok/s;    413 sec;
[2024-03-11 13:48:41,909 INFO] Step 5950/ 6200; acc: 94.2; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2366; bsz:  579/ 499/47; 9941/8570 tok/s;    416 sec;
[2024-03-11 13:48:45,630 INFO] Step 6000/ 6200; acc: 94.3; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2262; bsz:  560/ 483/45; 7525/6489 tok/s;    419 sec;
[2024-03-11 13:48:49,137 INFO] valid stats calculation
                           took: 3.50650691986084 s.
[2024-03-11 13:48:49,138 INFO] Train perplexity: 2.92256
[2024-03-11 13:48:49,138 INFO] Train accuracy: 78.2859
[2024-03-11 13:48:49,138 INFO] Sentences processed: 224332
[2024-03-11 13:48:49,138 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:48:49,138 INFO] Validation perplexity: 14717.9
[2024-03-11 13:48:49,138 INFO] Validation accuracy: 28.199
[2024-03-11 13:48:49,139 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_6000.pt
[2024-03-11 13:48:52,991 INFO] Step 6050/ 6200; acc: 94.2; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2367; bsz:  586/ 507/47; 3978/3444 tok/s;    427 sec;
[2024-03-11 13:48:55,853 INFO] Step 6100/ 6200; acc: 94.3; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2267; bsz:  557/ 483/45; 9727/8434 tok/s;    430 sec;
[2024-03-11 13:48:58,313 INFO] Step 6150/ 6200; acc: 94.5; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2372; bsz:  564/ 492/47; 11460/10009 tok/s;    432 sec;
[2024-03-11 13:49:00,814 INFO] Step 6200/ 6200; acc: 94.2; ppl:   1.2; xent: 0.2; lr: 1.00000; sents:    2371; bsz:  590/ 510/47; 11794/10206 tok/s;    435 sec;
[2024-03-11 13:49:04,406 INFO] valid stats calculation
                           took: 3.5911242961883545 s.
[2024-03-11 13:49:04,406 INFO] Train perplexity: 2.82177
[2024-03-11 13:49:04,406 INFO] Train accuracy: 78.932
[2024-03-11 13:49:04,406 INFO] Sentences processed: 233709
[2024-03-11 13:49:04,406 INFO] Average bsz:  569/ 494/47
[2024-03-11 13:49:04,406 INFO] Validation perplexity: 13626.1
[2024-03-11 13:49:04,406 INFO] Validation accuracy: 28.8408
[2024-03-11 13:49:04,407 INFO] Saving checkpoint tg-finetune/tg-finetune_1200_01_step_6200.pt
